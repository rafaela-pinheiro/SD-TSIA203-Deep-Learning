{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaht-FPA1Jvq"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "## Lab2: Train a Convolutional Neural Network (CNN).\n",
        "\n",
        "In this Lab session we will learn how to train a CNN from scratch for classifying MNIST digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UvxtTYHlVfRK"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCvhGxKWyN7"
      },
      "source": [
        "### Define LeNet\n",
        "\n",
        "![network architecture](https://www.researchgate.net/profile/Lucijano-Berus/publication/329891470/figure/fig1/AS:707347647307776@1545656229128/Architecture-of-LeNet-5-a-Convolutional-Neural-Network-for-digits-digits-recognition-An.ppm)\n",
        "\n",
        "Here we are going to define our first CNN which is **LeNet** in this case. This architecture has been introduced and is detailed in [this article](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf). To construct a LeNet we will be using some convolutional layers followed by some fully-connected layers. The convolutional layers can be simply defined using `torch.nn.Conv2d` module of `torch.nn` package. Details can be found [here](https://pytorch.org/docs/stable/nn.html#conv2d). Moreover, we will use pooling operation to reduce the size of convolutional feature maps. For this case we are going to use `torch.nn.functional.max_pool2d`. Details about maxpooling can be found [here](https://pytorch.org/docs/stable/nn.html#max-pool2d)\n",
        "\n",
        "Differently from our previous Lab, we will use a Rectified Linear Units (ReLU) as activation function with the help of `torch.nn.functional.relu`, replacing `torch.nn.Sigmoid`. Details about ReLU can be found [here](https://pytorch.org/docs/stable/nn.html#id26)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dMC_LDYdWkI7"
      },
      "outputs": [],
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "\n",
        "    # input channel = 1, output channels = 6, kernel size = 5\n",
        "    # input image size = (32, 32), image output size = (28, 28)\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) # stride=1, padding=0\n",
        "    self.pool1 = torch.nn.MaxPool2d(kernel_size=2) #stride = kernel_size\n",
        "\n",
        "    # input channel = 6, output channels = 16, kernel size = 5\n",
        "    # input image size = (14, 14), output image size = (10, 10)\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "    self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    # input dim = 5*5*16 ( H x W x C), output dim = 120\n",
        "    self.fc1 = torch.nn.Linear(in_features=5*5*16, out_features=120)\n",
        "    self.activation1 = torch.nn.ReLU()\n",
        "\n",
        "    # input dim = 120, output dim = 84\n",
        "    self.fc2 = torch.nn.Linear(in_features=120, out_features=84)\n",
        "    self.activation2 = torch.nn.ReLU()\n",
        "\n",
        "    # input dim = 84, output dim = 10\n",
        "    self.fc3 = torch.nn.Linear(in_features=84, out_features=10)\n",
        "    # self.activation3 = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.pad(x, (2, 2, 2, 2))\n",
        "    # Max Pooling with kernel size = 2\n",
        "    # output size = (14, 14)\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    # Max Pooling with kernel size = 2\n",
        "    # output size = (5, 5)\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    # flatten the feature maps into a long vector\n",
        "    x = x.view(x.shape[0], -1)\n",
        "\n",
        "    x =self.activation1(self.fc1(x))\n",
        "    x = self.activation2(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gChf6TvWonrV"
      },
      "source": [
        "### Define cost function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6j5UrBH3oek8"
      },
      "outputs": [],
      "source": [
        "def get_cost_function():\n",
        "  cost_function = torch.nn.CrossEntropyLoss()\n",
        "  return cost_function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2TjXeVdorV9"
      },
      "source": [
        "### Define the optimizer\n",
        "\n",
        "We will use SGD with learning rate-lr, weight_decay=wd and  momentum=momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hBZN-WPboulR"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(net, lr, wd, momentum):\n",
        "  optimizer =  torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTkfrV64oxIL"
      },
      "source": [
        "### Train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t-sE5vFio0lf"
      },
      "outputs": [],
      "source": [
        "def test(net, data_loader, cost_function, device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      # Load data into GPU\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      # Apply the loss\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      # Better print something\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = outputs.max(1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
        "\n",
        "\n",
        "def train(net,data_loader,optimizer,cost_function, device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "\n",
        "  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "    # Load data into GPU\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # Apply the loss\n",
        "    loss = cost_function(outputs,targets)\n",
        "\n",
        "    # Reset the optimizer\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Better print something, no?\n",
        "    samples+=inputs.shape[0]\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(1)\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6IT0Lsgo8AM"
      },
      "source": [
        "### Define the function that fetches a data loader that is then used during iterative training.\n",
        "\n",
        "We will learn a new thing in this function as how to Normalize the inputs given to the network.\n",
        "\n",
        "***Why Normalization is needed***?\n",
        "\n",
        "To have nice and stable training of the network it is recommended to normalize the network inputs between \\[-1, 1\\].\n",
        "\n",
        "***How it can be done***?\n",
        "\n",
        "This can be simply done using `torchvision.transforms.Normalize()` transform. Details can be found [here](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qDxpo6uVo_8k"
      },
      "outputs": [],
      "source": [
        "def get_data(batch_size, test_batch_size=256):\n",
        "\n",
        "  # Prepare data transformations and then combine them sequentially\n",
        "  transform = list()\n",
        "  transform.append(T.ToTensor())                            # converts Numpy to Pytorch Tensor\n",
        "  transform.append(T.Normalize(mean=[0.5], std=[0.5]))      # Normalizes the Tensors between [-1, 1]\n",
        "  transform = T.Compose(transform)                          # Composes the above transformations into one.\n",
        "\n",
        "  # Load data\n",
        "  full_training_data = torchvision.datasets.MNIST('./data', train=True, transform=transform, download=True)\n",
        "  test_data = torchvision.datasets.MNIST('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "  # Create train and validation splits\n",
        "  num_samples = len(full_training_data)\n",
        "  training_samples = int(num_samples*0.5+1)\n",
        "  validation_samples = num_samples - training_samples\n",
        "\n",
        "  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
        "\n",
        "  # Initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(validation_data, test_batch_size, shuffle=False)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcB8f0AsY4n"
      },
      "source": [
        "### Wrapping everything up\n",
        "\n",
        "Finally, we need a main function which initializes everything + the needed hyperparameters and loops over multiple epochs (printing the results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ip_R-hruse0Q"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Input arguments\n",
        "  batch_size: Size of a mini-batch\n",
        "  device: GPU where you want to train your network\n",
        "  weight_decay: Weight decay co-efficient for regularization of weights\n",
        "  momentum: Momentum for SGD optimizer\n",
        "  epochs: Number of epochs for training the network\n",
        "'''\n",
        "\n",
        "def main(batch_size=128,\n",
        "          device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),\n",
        "          learning_rate=0.01,\n",
        "          weight_decay=0.000001,\n",
        "          momentum=0.9,\n",
        "          epochs=50,\n",
        "          net = None):\n",
        "\n",
        "  train_loader, val_loader, test_loader = get_data(batch_size)\n",
        "\n",
        "  # TODO for defining LeNet-5 and moving it to the GPU\n",
        "  # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # device = torch.device(\"cpu\")\n",
        "  net = LeNet().to(device)\n",
        "\n",
        "  optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "\n",
        "  cost_function = get_cost_function()\n",
        "\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  for e in range(epochs):\n",
        "    train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function)\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "  print('After training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "  val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "  test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  return net, test_loader, train_loss, train_accuracy, val_loss, val_accuracy, test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltdCMiB3t18h"
      },
      "source": [
        "Lets train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6d-z20H4tziL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before training:\n",
            "\t Training loss 0.01806, Training accuracy 7.87\n",
            "\t Validation loss 0.00906, Validation accuracy 7.88\n",
            "\t Test loss 0.00922, Test accuracy 8.52\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.00700, Training accuracy 69.50\n",
            "\t Validation loss 0.00079, Validation accuracy 94.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.00127, Training accuracy 94.83\n",
            "\t Validation loss 0.00049, Validation accuracy 96.33\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Training loss 0.00083, Training accuracy 96.79\n",
            "\t Validation loss 0.00039, Validation accuracy 96.82\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Training loss 0.00066, Training accuracy 97.30\n",
            "\t Validation loss 0.00035, Validation accuracy 97.19\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Training loss 0.00052, Training accuracy 97.94\n",
            "\t Validation loss 0.00035, Validation accuracy 97.30\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Training loss 0.00042, Training accuracy 98.22\n",
            "\t Validation loss 0.00032, Validation accuracy 97.44\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Training loss 0.00034, Training accuracy 98.61\n",
            "\t Validation loss 0.00024, Validation accuracy 98.19\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Training loss 0.00031, Training accuracy 98.75\n",
            "\t Validation loss 0.00035, Validation accuracy 97.51\n",
            "-----------------------------------------------------\n",
            "Epoch: 9\n",
            "\t Training loss 0.00024, Training accuracy 99.04\n",
            "\t Validation loss 0.00024, Validation accuracy 98.20\n",
            "-----------------------------------------------------\n",
            "Epoch: 10\n",
            "\t Training loss 0.00020, Training accuracy 99.18\n",
            "\t Validation loss 0.00024, Validation accuracy 98.28\n",
            "-----------------------------------------------------\n",
            "Epoch: 11\n",
            "\t Training loss 0.00017, Training accuracy 99.32\n",
            "\t Validation loss 0.00024, Validation accuracy 98.25\n",
            "-----------------------------------------------------\n",
            "Epoch: 12\n",
            "\t Training loss 0.00016, Training accuracy 99.31\n",
            "\t Validation loss 0.00025, Validation accuracy 98.30\n",
            "-----------------------------------------------------\n",
            "Epoch: 13\n",
            "\t Training loss 0.00014, Training accuracy 99.40\n",
            "\t Validation loss 0.00024, Validation accuracy 98.33\n",
            "-----------------------------------------------------\n",
            "Epoch: 14\n",
            "\t Training loss 0.00012, Training accuracy 99.54\n",
            "\t Validation loss 0.00025, Validation accuracy 98.33\n",
            "-----------------------------------------------------\n",
            "Epoch: 15\n",
            "\t Training loss 0.00010, Training accuracy 99.61\n",
            "\t Validation loss 0.00023, Validation accuracy 98.47\n",
            "-----------------------------------------------------\n",
            "Epoch: 16\n",
            "\t Training loss 0.00008, Training accuracy 99.68\n",
            "\t Validation loss 0.00023, Validation accuracy 98.45\n",
            "-----------------------------------------------------\n",
            "Epoch: 17\n",
            "\t Training loss 0.00005, Training accuracy 99.83\n",
            "\t Validation loss 0.00027, Validation accuracy 98.33\n",
            "-----------------------------------------------------\n",
            "Epoch: 18\n",
            "\t Training loss 0.00006, Training accuracy 99.77\n",
            "\t Validation loss 0.00027, Validation accuracy 98.31\n",
            "-----------------------------------------------------\n",
            "Epoch: 19\n",
            "\t Training loss 0.00004, Training accuracy 99.85\n",
            "\t Validation loss 0.00025, Validation accuracy 98.51\n",
            "-----------------------------------------------------\n",
            "Epoch: 20\n",
            "\t Training loss 0.00002, Training accuracy 99.94\n",
            "\t Validation loss 0.00028, Validation accuracy 98.43\n",
            "-----------------------------------------------------\n",
            "Epoch: 21\n",
            "\t Training loss 0.00003, Training accuracy 99.88\n",
            "\t Validation loss 0.00030, Validation accuracy 98.42\n",
            "-----------------------------------------------------\n",
            "Epoch: 22\n",
            "\t Training loss 0.00004, Training accuracy 99.87\n",
            "\t Validation loss 0.00026, Validation accuracy 98.52\n",
            "-----------------------------------------------------\n",
            "Epoch: 23\n",
            "\t Training loss 0.00003, Training accuracy 99.90\n",
            "\t Validation loss 0.00031, Validation accuracy 98.33\n",
            "-----------------------------------------------------\n",
            "Epoch: 24\n",
            "\t Training loss 0.00001, Training accuracy 99.99\n",
            "\t Validation loss 0.00026, Validation accuracy 98.60\n",
            "-----------------------------------------------------\n",
            "Epoch: 25\n",
            "\t Training loss 0.00001, Training accuracy 99.99\n",
            "\t Validation loss 0.00028, Validation accuracy 98.50\n",
            "-----------------------------------------------------\n",
            "Epoch: 26\n",
            "\t Training loss 0.00001, Training accuracy 99.99\n",
            "\t Validation loss 0.00028, Validation accuracy 98.54\n",
            "-----------------------------------------------------\n",
            "Epoch: 27\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00027, Validation accuracy 98.60\n",
            "-----------------------------------------------------\n",
            "Epoch: 28\n",
            "\t Training loss 0.00000, Training accuracy 99.99\n",
            "\t Validation loss 0.00027, Validation accuracy 98.57\n",
            "-----------------------------------------------------\n",
            "Epoch: 29\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00027, Validation accuracy 98.62\n",
            "-----------------------------------------------------\n",
            "Epoch: 30\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.57\n",
            "-----------------------------------------------------\n",
            "Epoch: 31\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00028, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 32\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00028, Validation accuracy 98.61\n",
            "-----------------------------------------------------\n",
            "Epoch: 33\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00029, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 34\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00029, Validation accuracy 98.61\n",
            "-----------------------------------------------------\n",
            "Epoch: 35\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00029, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 36\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00029, Validation accuracy 98.60\n",
            "-----------------------------------------------------\n",
            "Epoch: 37\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.58\n",
            "-----------------------------------------------------\n",
            "Epoch: 38\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 39\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 40\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.60\n",
            "-----------------------------------------------------\n",
            "Epoch: 41\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 42\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.58\n",
            "-----------------------------------------------------\n",
            "Epoch: 43\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 44\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00030, Validation accuracy 98.60\n",
            "-----------------------------------------------------\n",
            "Epoch: 45\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00031, Validation accuracy 98.58\n",
            "-----------------------------------------------------\n",
            "Epoch: 46\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00031, Validation accuracy 98.60\n",
            "-----------------------------------------------------\n",
            "Epoch: 47\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00031, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 48\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00031, Validation accuracy 98.58\n",
            "-----------------------------------------------------\n",
            "Epoch: 49\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00031, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 50\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00031, Validation accuracy 98.59\n",
            "-----------------------------------------------------\n",
            "After training:\n",
            "\t Training loss 0.00000, Training accuracy 100.00\n",
            "\t Validation loss 0.00031, Validation accuracy 98.59\n",
            "\t Test loss 0.00024, Test accuracy 98.72\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# main(**config,net=LeNet().to(config['device']), save_path='lenet.pth')\n",
        "net, test_loader, train_loss, train_accuracy, val_loss, val_accuracy, test_loss, test_accuracy = main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQBDT48CKMVC"
      },
      "source": [
        "Check which MNIST digit is most frequently confused with which other digit (e.g. plot a confusion matrix). Can you explain why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X92ANv6uPea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_confusion_matrix(net, data_loader, device='cpu'):\n",
        "    net.eval()  # Switch to eval mode\n",
        "    all_targets = []\n",
        "    all_predicted = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "\n",
        "    return confusion_matrix(all_targets, all_predicted)\n",
        "\n",
        "\n",
        "cm = get_confusion_matrix(net, test_loader, device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),)\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix on MNIST Test Set\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Answer**: We can see the hardest digits to classify are 5, 6 and 8. Due to their shapes and multiple aways of writing them, it can be difficult for the model to correctly classify them by analysing a few features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voRqJpgVuQWX"
      },
      "source": [
        "The LeNet5 architecture can also be implemented using the sequential API ([see documentation](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)). Reimplement it with this API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i3-pC5xAyu5"
      },
      "source": [
        "## Experiments\n",
        "\n",
        "* Implement adaptive early stopping: if the validation loss did not decrease for K consecutive epochs, stop training.\n",
        "* Change dataset in order to evaluate the LeNet5 network on cifar10 dataset. You can have a look at the pytorch documentation to easily access the cifar10 dataset.\n",
        "* Try to improve performance with:\n",
        "   *   data-augmentation\n",
        "   *   dropout\n",
        "* Implement the resnet18 architecture using the Resnet18 class from pytorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_cifar10(batch_size, test_batch_size=256, augmentation=False):\n",
        "\n",
        "  # Prepare data transformations and then combine them sequentially\n",
        "  transform = list()\n",
        "  transform.append(T.ToTensor())                            # converts Numpy to Pytorch Tensor\n",
        "  if augmentation:\n",
        "    transform.append(v2.RandomResizedCrop(size=32, antialias=True))   # Randomly crops the image to (32, 32) \n",
        "    transform.append(v2.RandomHorizontalFlip(p=0.5))                  # Randomly flips the image horizontally\n",
        "  transform.append(T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]))      # Normalizes the Tensors between [-1, 1]\n",
        "  transform = T.Compose(transform)                          # Composes the above transformations into one.\n",
        "\n",
        "  # Load data\n",
        "  full_training_data = torchvision.datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
        "  test_data = torchvision.datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "\n",
        "  # Create train and validation splits\n",
        "  num_samples = len(full_training_data)\n",
        "  training_samples = int(num_samples*0.5+1)\n",
        "  validation_samples = num_samples - training_samples\n",
        "\n",
        "  training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
        "\n",
        "  # Initialize dataloaders\n",
        "  train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(validation_data, test_batch_size, shuffle=False)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, test_batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LeNetCIFAR10(torch.nn.Module):\n",
        "  def __init__(self, dropout = False):\n",
        "    super(LeNetCIFAR10, self).__init__()\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5) # input 28x28 with 3 channels (RGB)\n",
        "    # self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "    # self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    # input dim = 5*5*16 ( H x W x C), output dim = 120\n",
        "    self.fc1 = torch.nn.Linear(in_features=5*5*16, out_features=120)\n",
        "    # self.activation1 = torch.nn.ReLU()\n",
        "\n",
        "    # input dim = 120, output dim = 84\n",
        "    self.fc2 = torch.nn.Linear(in_features=120, out_features=84)\n",
        "    # self.activation2 = torch.nn.ReLU()\n",
        "\n",
        "    # input dim = 84, output dim = 10\n",
        "    self.fc3 = torch.nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    # dropout\n",
        "    self.dropout = dropout\n",
        "    if self.dropout:\n",
        "      self.dropout1 = torch.nn.Dropout(p=0.5)\n",
        "      self.dropout2 = torch.nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "    # flatten the feature maps into a long vector\n",
        "    x = x.view(x.shape[0], -1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    if self.dropout:\n",
        "      x = self.dropout1(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    if self.dropout:\n",
        "      x = self.dropout2(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# early stopping\n",
        "def main_early_stop(batch_size=128,\n",
        "                    device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),\n",
        "                    learning_rate=0.01,\n",
        "                    weight_decay=0.000001,\n",
        "                    momentum=0.9,\n",
        "                    epochs=50,\n",
        "                    early_stopping=False,\n",
        "                    data_augmentation=False,\n",
        "                    dropout=False,\n",
        "                    cifar10 = False,\n",
        "                    resnet18 = False,\n",
        "                    K = 3):\n",
        "\n",
        "    if cifar10:\n",
        "        net = LeNetCIFAR10(dropout).to(device)\n",
        "        train_loader, val_loader, test_loader = get_data_cifar10(batch_size, augmentation=data_augmentation)\n",
        "    elif resnet18:\n",
        "        # use ResNet18 model\n",
        "        net = resnet18().to(device)\n",
        "        train_loader, val_loader, test_loader = get_data(batch_size)\n",
        "    else:\n",
        "        net = LeNet().to(device)\n",
        "        train_loader, val_loader, test_loader = get_data(batch_size)        \n",
        "\n",
        "    optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "\n",
        "    cost_function = get_cost_function()\n",
        "\n",
        "    print('Before training:')\n",
        "    train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "    if early_stopping:\n",
        "        # early stopping parameters\n",
        "        last_val_loss = torch.inf\n",
        "        last_val_acc = 0\n",
        "        es = 0\n",
        "        for e in range(epochs):\n",
        "            train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function, device)\n",
        "            val_loss, val_accuracy = test(net, val_loader, cost_function, device)\n",
        "\n",
        "            print('Epoch: {:d}'.format(e+1))\n",
        "            print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "            print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "            # Early stopping\n",
        "            if val_loss >= last_val_loss or abs(val_accuracy - last_val_acc) <= 0.01:\n",
        "                print('Validation loss increased from {:.2f} to {:.2f}'.format(last_val_loss, val_loss))\n",
        "                es += 1\n",
        "            else:\n",
        "                es = 0\n",
        "            last_val_loss = val_loss\n",
        "            last_val_acc = val_accuracy\n",
        "            if es >= K:\n",
        "                print('Early stopping at epoch {:d}'.format(e+1))\n",
        "                break\n",
        "            print('-----------------------------------------------------')            \n",
        "\n",
        "    else:\n",
        "        for e in range(epochs):\n",
        "            train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function)\n",
        "            val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "            print('Epoch: {:d}'.format(e+1))\n",
        "            print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "            print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "            print('-----------------------------------------------------')\n",
        "\n",
        "    print('After training:')\n",
        "    train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "    return net, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# early stopping\n",
        "def main_early_stop(batch_size=128,\n",
        "                    device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),\n",
        "                    learning_rate=0.01,\n",
        "                    weight_decay=0.000001,\n",
        "                    momentum=0.9,\n",
        "                    epochs=50,\n",
        "                    early_stopping=False,\n",
        "                    data_augmentation=False,\n",
        "                    cifar10 = False,\n",
        "                    resnet18 = False,\n",
        "                    K = 3):\n",
        "\n",
        "    if cifar10:\n",
        "        net = LeNetCIFAR10().to(device)\n",
        "        train_loader, val_loader, test_loader = get_data_cifar10(batch_size, augmentation=data_augmentation)\n",
        "    elif resnet18:\n",
        "        # use ResNet18 model\n",
        "        net = resnet18().to(device)\n",
        "        train_loader, val_loader, test_loader = get_data(batch_size)\n",
        "    else:\n",
        "        net = LeNet().to(device)\n",
        "        train_loader, val_loader, test_loader = get_data(batch_size)        \n",
        "\n",
        "    optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "\n",
        "    cost_function = get_cost_function()\n",
        "\n",
        "    print('Before training:')\n",
        "    train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "    if early_stopping:\n",
        "        # early stopping parameters\n",
        "        last_val_loss = torch.inf\n",
        "        last_val_acc = 0\n",
        "        es = 0\n",
        "        for e in range(epochs):\n",
        "            train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function, device)\n",
        "            val_loss, val_accuracy = test(net, val_loader, cost_function, device)\n",
        "\n",
        "            print('Epoch: {:d}'.format(e+1))\n",
        "            print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "            print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "            \n",
        "            # Early stopping\n",
        "            if val_loss < last_val_loss - 1e-4:\n",
        "                es = 0\n",
        "                last_val_loss = val_loss\n",
        "                print('Validation loss increased from {:.2f} to {:.2f}'.format(last_val_loss, val_loss))\n",
        "            else:\n",
        "                es += 1\n",
        "            # last_val_loss = val_loss\n",
        "            # last_val_acc = val_accuracy\n",
        "            if es >= K:\n",
        "                print('Early stopping at epoch {:d}'.format(e+1))\n",
        "                break\n",
        "            print('-----------------------------------------------------')            \n",
        "\n",
        "    else:\n",
        "        for e in range(epochs):\n",
        "            train_loss, train_accuracy = train(net, train_loader, optimizer, cost_function)\n",
        "            val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "            print('Epoch: {:d}'.format(e+1))\n",
        "            print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "            print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "            print('-----------------------------------------------------')\n",
        "\n",
        "    print('After training:')\n",
        "    train_loss, train_accuracy = test(net, train_loader, cost_function)\n",
        "    val_loss, val_accuracy = test(net, val_loader, cost_function)\n",
        "    test_loss, test_accuracy = test(net, test_loader, cost_function)\n",
        "\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Validation loss {:.5f}, Validation accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('\\t Test loss {:.5f}, Test accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "\n",
        "    return net, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before training:\n",
            "\t Training loss 0.01803, Training accuracy 15.01\n",
            "\t Validation loss 0.00905, Validation accuracy 15.33\n",
            "\t Test loss 0.00920, Test accuracy 16.21\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.00667, Training accuracy 71.35\n",
            "\t Validation loss 0.00086, Validation accuracy 93.25\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.00115, Training accuracy 95.54\n",
            "\t Validation loss 0.00045, Validation accuracy 96.70\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Training loss 0.00072, Training accuracy 97.09\n",
            "\t Validation loss 0.00045, Validation accuracy 96.49\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Training loss 0.00057, Training accuracy 97.65\n",
            "\t Validation loss 0.00035, Validation accuracy 97.32\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Training loss 0.00044, Training accuracy 98.24\n",
            "\t Validation loss 0.00030, Validation accuracy 97.69\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Training loss 0.00037, Training accuracy 98.48\n",
            "\t Validation loss 0.00028, Validation accuracy 97.79\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Training loss 0.00030, Training accuracy 98.82\n",
            "\t Validation loss 0.00025, Validation accuracy 98.03\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Training loss 0.00026, Training accuracy 98.94\n",
            "\t Validation loss 0.00025, Validation accuracy 98.16\n",
            "Early stopping at epoch 8\n",
            "After training:\n",
            "\t Training loss 0.00019, Training accuracy 99.26\n",
            "\t Validation loss 0.00025, Validation accuracy 98.16\n",
            "\t Test loss 0.00019, Test accuracy 98.41\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# early stopping\n",
        "_, _ = main_early_stop(early_stopping=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before training:\n",
            "\t Training loss 0.01808, Training accuracy 10.07\n",
            "\t Validation loss 0.00904, Validation accuracy 9.92\n",
            "\t Test loss 0.00922, Test accuracy 10.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.01757, Training accuracy 15.80\n",
            "\t Validation loss 0.00800, Validation accuracy 24.26\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.01484, Training accuracy 29.77\n",
            "\t Validation loss 0.00680, Validation accuracy 36.44\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Training loss 0.01274, Training accuracy 40.09\n",
            "\t Validation loss 0.00614, Validation accuracy 42.36\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Training loss 0.01173, Training accuracy 45.47\n",
            "\t Validation loss 0.00591, Validation accuracy 45.30\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Training loss 0.01095, Training accuracy 49.37\n",
            "\t Validation loss 0.00530, Validation accuracy 51.50\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Training loss 0.01027, Training accuracy 52.87\n",
            "\t Validation loss 0.00527, Validation accuracy 51.81\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Training loss 0.00979, Training accuracy 55.31\n",
            "\t Validation loss 0.00501, Validation accuracy 54.67\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Training loss 0.00932, Training accuracy 57.71\n",
            "\t Validation loss 0.00531, Validation accuracy 53.26\n",
            "-----------------------------------------------------\n",
            "Epoch: 9\n",
            "\t Training loss 0.00895, Training accuracy 59.12\n",
            "\t Validation loss 0.00478, Validation accuracy 56.79\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 10\n",
            "\t Training loss 0.00844, Training accuracy 61.81\n",
            "\t Validation loss 0.00489, Validation accuracy 56.46\n",
            "-----------------------------------------------------\n",
            "Epoch: 11\n",
            "\t Training loss 0.00809, Training accuracy 63.52\n",
            "\t Validation loss 0.00453, Validation accuracy 59.93\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 12\n",
            "\t Training loss 0.00776, Training accuracy 64.78\n",
            "\t Validation loss 0.00480, Validation accuracy 57.96\n",
            "-----------------------------------------------------\n",
            "Epoch: 13\n",
            "\t Training loss 0.00734, Training accuracy 66.73\n",
            "\t Validation loss 0.00460, Validation accuracy 59.63\n",
            "-----------------------------------------------------\n",
            "Epoch: 14\n",
            "\t Training loss 0.00703, Training accuracy 68.06\n",
            "\t Validation loss 0.00488, Validation accuracy 57.19\n",
            "Early stopping at epoch 14\n",
            "After training:\n",
            "\t Training loss 0.00715, Training accuracy 67.81\n",
            "\t Validation loss 0.00488, Validation accuracy 57.19\n",
            "\t Test loss 0.00498, Test accuracy 56.94\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# cifar10, just early stopping \n",
        "_, _ = main_early_stop(early_stopping=True, cifar10=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before training:\n",
            "\t Training loss 0.01807, Training accuracy 9.96\n",
            "\t Validation loss 0.00903, Validation accuracy 10.04\n",
            "\t Test loss 0.00922, Test accuracy 10.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.01801, Training accuracy 11.71\n",
            "\t Validation loss 0.00888, Validation accuracy 16.56\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.01709, Training accuracy 17.76\n",
            "\t Validation loss 0.00815, Validation accuracy 21.90\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Training loss 0.01616, Training accuracy 21.18\n",
            "\t Validation loss 0.00778, Validation accuracy 23.60\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Training loss 0.01572, Training accuracy 23.78\n",
            "\t Validation loss 0.00766, Validation accuracy 26.36\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Training loss 0.01539, Training accuracy 25.83\n",
            "\t Validation loss 0.00745, Validation accuracy 28.92\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Training loss 0.01511, Training accuracy 27.10\n",
            "\t Validation loss 0.00744, Validation accuracy 29.23\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Training loss 0.01487, Training accuracy 28.67\n",
            "\t Validation loss 0.00716, Validation accuracy 32.10\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Training loss 0.01467, Training accuracy 29.61\n",
            "\t Validation loss 0.00705, Validation accuracy 32.81\n",
            "-----------------------------------------------------\n",
            "Epoch: 9\n",
            "\t Training loss 0.01449, Training accuracy 30.97\n",
            "\t Validation loss 0.00703, Validation accuracy 33.59\n",
            "-----------------------------------------------------\n",
            "Epoch: 10\n",
            "\t Training loss 0.01443, Training accuracy 31.43\n",
            "\t Validation loss 0.00709, Validation accuracy 33.05\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 11\n",
            "\t Training loss 0.01426, Training accuracy 32.78\n",
            "\t Validation loss 0.00686, Validation accuracy 34.73\n",
            "-----------------------------------------------------\n",
            "Epoch: 12\n",
            "\t Training loss 0.01414, Training accuracy 32.72\n",
            "\t Validation loss 0.00684, Validation accuracy 35.33\n",
            "-----------------------------------------------------\n",
            "Epoch: 13\n",
            "\t Training loss 0.01401, Training accuracy 33.77\n",
            "\t Validation loss 0.00679, Validation accuracy 35.37\n",
            "-----------------------------------------------------\n",
            "Epoch: 14\n",
            "\t Training loss 0.01394, Training accuracy 34.05\n",
            "\t Validation loss 0.00670, Validation accuracy 36.67\n",
            "-----------------------------------------------------\n",
            "Epoch: 15\n",
            "\t Training loss 0.01384, Training accuracy 34.59\n",
            "\t Validation loss 0.00675, Validation accuracy 35.76\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 16\n",
            "\t Training loss 0.01380, Training accuracy 34.99\n",
            "\t Validation loss 0.00664, Validation accuracy 37.35\n",
            "-----------------------------------------------------\n",
            "Epoch: 17\n",
            "\t Training loss 0.01378, Training accuracy 35.09\n",
            "\t Validation loss 0.00666, Validation accuracy 37.29\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 18\n",
            "\t Training loss 0.01375, Training accuracy 35.30\n",
            "\t Validation loss 0.00658, Validation accuracy 38.40\n",
            "-----------------------------------------------------\n",
            "Epoch: 19\n",
            "\t Training loss 0.01369, Training accuracy 35.72\n",
            "\t Validation loss 0.00655, Validation accuracy 38.77\n",
            "-----------------------------------------------------\n",
            "Epoch: 20\n",
            "\t Training loss 0.01358, Training accuracy 36.09\n",
            "\t Validation loss 0.00654, Validation accuracy 38.70\n",
            "-----------------------------------------------------\n",
            "Epoch: 21\n",
            "\t Training loss 0.01352, Training accuracy 36.53\n",
            "\t Validation loss 0.00649, Validation accuracy 39.97\n",
            "-----------------------------------------------------\n",
            "Epoch: 22\n",
            "\t Training loss 0.01342, Training accuracy 37.25\n",
            "\t Validation loss 0.00647, Validation accuracy 39.65\n",
            "-----------------------------------------------------\n",
            "Epoch: 23\n",
            "\t Training loss 0.01350, Training accuracy 36.95\n",
            "\t Validation loss 0.00649, Validation accuracy 39.11\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 24\n",
            "\t Training loss 0.01343, Training accuracy 36.93\n",
            "\t Validation loss 0.00636, Validation accuracy 40.53\n",
            "-----------------------------------------------------\n",
            "Epoch: 25\n",
            "\t Training loss 0.01326, Training accuracy 38.28\n",
            "\t Validation loss 0.00639, Validation accuracy 40.05\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 26\n",
            "\t Training loss 0.01327, Training accuracy 38.51\n",
            "\t Validation loss 0.00640, Validation accuracy 40.32\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 27\n",
            "\t Training loss 0.01324, Training accuracy 38.43\n",
            "\t Validation loss 0.00635, Validation accuracy 39.75\n",
            "-----------------------------------------------------\n",
            "Epoch: 28\n",
            "\t Training loss 0.01323, Training accuracy 38.28\n",
            "\t Validation loss 0.00634, Validation accuracy 40.85\n",
            "-----------------------------------------------------\n",
            "Epoch: 29\n",
            "\t Training loss 0.01322, Training accuracy 39.08\n",
            "\t Validation loss 0.00630, Validation accuracy 41.02\n",
            "-----------------------------------------------------\n",
            "Epoch: 30\n",
            "\t Training loss 0.01322, Training accuracy 38.75\n",
            "\t Validation loss 0.00629, Validation accuracy 41.58\n",
            "-----------------------------------------------------\n",
            "Epoch: 31\n",
            "\t Training loss 0.01308, Training accuracy 39.12\n",
            "\t Validation loss 0.00628, Validation accuracy 41.54\n",
            "-----------------------------------------------------\n",
            "Epoch: 32\n",
            "\t Training loss 0.01301, Training accuracy 39.43\n",
            "\t Validation loss 0.00628, Validation accuracy 41.59\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 33\n",
            "\t Training loss 0.01312, Training accuracy 38.78\n",
            "\t Validation loss 0.00628, Validation accuracy 41.93\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 34\n",
            "\t Training loss 0.01305, Training accuracy 39.75\n",
            "\t Validation loss 0.00622, Validation accuracy 41.87\n",
            "-----------------------------------------------------\n",
            "Epoch: 35\n",
            "\t Training loss 0.01305, Training accuracy 39.61\n",
            "\t Validation loss 0.00629, Validation accuracy 41.35\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 36\n",
            "\t Training loss 0.01299, Training accuracy 39.79\n",
            "\t Validation loss 0.00618, Validation accuracy 42.14\n",
            "-----------------------------------------------------\n",
            "Epoch: 37\n",
            "\t Training loss 0.01296, Training accuracy 40.49\n",
            "\t Validation loss 0.00619, Validation accuracy 42.93\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 38\n",
            "\t Training loss 0.01300, Training accuracy 39.63\n",
            "\t Validation loss 0.00622, Validation accuracy 42.76\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 39\n",
            "\t Training loss 0.01301, Training accuracy 39.78\n",
            "\t Validation loss 0.00616, Validation accuracy 43.03\n",
            "-----------------------------------------------------\n",
            "Epoch: 40\n",
            "\t Training loss 0.01288, Training accuracy 40.52\n",
            "\t Validation loss 0.00613, Validation accuracy 42.85\n",
            "-----------------------------------------------------\n",
            "Epoch: 41\n",
            "\t Training loss 0.01303, Training accuracy 39.74\n",
            "\t Validation loss 0.00616, Validation accuracy 42.59\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 42\n",
            "\t Training loss 0.01280, Training accuracy 40.69\n",
            "\t Validation loss 0.00612, Validation accuracy 43.53\n",
            "-----------------------------------------------------\n",
            "Epoch: 43\n",
            "\t Training loss 0.01286, Training accuracy 40.81\n",
            "\t Validation loss 0.00611, Validation accuracy 43.22\n",
            "-----------------------------------------------------\n",
            "Epoch: 44\n",
            "\t Training loss 0.01283, Training accuracy 40.75\n",
            "\t Validation loss 0.00616, Validation accuracy 42.61\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 45\n",
            "\t Training loss 0.01280, Training accuracy 41.17\n",
            "\t Validation loss 0.00621, Validation accuracy 42.56\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 46\n",
            "\t Training loss 0.01279, Training accuracy 41.08\n",
            "\t Validation loss 0.00611, Validation accuracy 43.29\n",
            "-----------------------------------------------------\n",
            "Epoch: 47\n",
            "\t Training loss 0.01277, Training accuracy 41.30\n",
            "\t Validation loss 0.00609, Validation accuracy 43.54\n",
            "-----------------------------------------------------\n",
            "Epoch: 48\n",
            "\t Training loss 0.01279, Training accuracy 40.96\n",
            "\t Validation loss 0.00605, Validation accuracy 44.09\n",
            "-----------------------------------------------------\n",
            "Epoch: 49\n",
            "\t Training loss 0.01272, Training accuracy 41.46\n",
            "\t Validation loss 0.00611, Validation accuracy 43.39\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 50\n",
            "\t Training loss 0.01269, Training accuracy 41.55\n",
            "\t Validation loss 0.00611, Validation accuracy 43.21\n",
            "-----------------------------------------------------\n",
            "After training:\n",
            "\t Training loss 0.01206, Training accuracy 43.89\n",
            "\t Validation loss 0.00611, Validation accuracy 43.17\n",
            "\t Test loss 0.00618, Test accuracy 43.24\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# cifar10, early stopping + data augmentation + dropout\n",
        "_, _ = main_early_stop(early_stopping=True, data_augmentation=True, dropout=True, cifar10=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before training:\n",
            "\t Training loss 0.01806, Training accuracy 9.90\n",
            "\t Validation loss 0.00903, Validation accuracy 10.16\n",
            "\t Test loss 0.00922, Test accuracy 10.03\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.01777, Training accuracy 14.63\n",
            "\t Validation loss 0.00837, Validation accuracy 22.26\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.01514, Training accuracy 29.21\n",
            "\t Validation loss 0.00674, Validation accuracy 37.35\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Training loss 0.01309, Training accuracy 38.59\n",
            "\t Validation loss 0.00623, Validation accuracy 41.98\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Training loss 0.01210, Training accuracy 43.51\n",
            "\t Validation loss 0.00614, Validation accuracy 42.06\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Training loss 0.01160, Training accuracy 46.22\n",
            "\t Validation loss 0.00574, Validation accuracy 46.89\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Training loss 0.01100, Training accuracy 48.67\n",
            "\t Validation loss 0.00566, Validation accuracy 48.19\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Training loss 0.01049, Training accuracy 51.26\n",
            "\t Validation loss 0.00529, Validation accuracy 51.65\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Training loss 0.01008, Training accuracy 53.50\n",
            "\t Validation loss 0.00509, Validation accuracy 53.47\n",
            "-----------------------------------------------------\n",
            "Epoch: 9\n",
            "\t Training loss 0.00955, Training accuracy 56.03\n",
            "\t Validation loss 0.00513, Validation accuracy 52.61\n",
            "Validation loss increased from 0.01 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 10\n",
            "\t Training loss 0.00917, Training accuracy 58.15\n",
            "\t Validation loss 0.00485, Validation accuracy 56.45\n",
            "-----------------------------------------------------\n",
            "Epoch: 11\n",
            "\t Training loss 0.00874, Training accuracy 59.96\n",
            "\t Validation loss 0.00498, Validation accuracy 55.04\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 12\n",
            "\t Training loss 0.00840, Training accuracy 61.69\n",
            "\t Validation loss 0.00462, Validation accuracy 58.29\n",
            "-----------------------------------------------------\n",
            "Epoch: 13\n",
            "\t Training loss 0.00801, Training accuracy 63.71\n",
            "\t Validation loss 0.00475, Validation accuracy 57.76\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 14\n",
            "\t Training loss 0.00762, Training accuracy 65.24\n",
            "\t Validation loss 0.00469, Validation accuracy 58.71\n",
            "-----------------------------------------------------\n",
            "Epoch: 15\n",
            "\t Training loss 0.00745, Training accuracy 66.13\n",
            "\t Validation loss 0.00472, Validation accuracy 58.97\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 16\n",
            "\t Training loss 0.00709, Training accuracy 67.99\n",
            "\t Validation loss 0.00457, Validation accuracy 60.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 17\n",
            "\t Training loss 0.00678, Training accuracy 69.17\n",
            "\t Validation loss 0.00465, Validation accuracy 59.85\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 18\n",
            "\t Training loss 0.00650, Training accuracy 70.39\n",
            "\t Validation loss 0.00503, Validation accuracy 57.93\n",
            "Validation loss increased from 0.00 to 0.01\n",
            "-----------------------------------------------------\n",
            "Epoch: 19\n",
            "\t Training loss 0.00624, Training accuracy 71.61\n",
            "\t Validation loss 0.00472, Validation accuracy 59.89\n",
            "-----------------------------------------------------\n",
            "Epoch: 20\n",
            "\t Training loss 0.00588, Training accuracy 73.36\n",
            "\t Validation loss 0.00474, Validation accuracy 60.50\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 21\n",
            "\t Training loss 0.00567, Training accuracy 74.09\n",
            "\t Validation loss 0.00486, Validation accuracy 59.84\n",
            "Validation loss increased from 0.00 to 0.00\n",
            "-----------------------------------------------------\n",
            "Epoch: 22\n",
            "\t Training loss 0.00527, Training accuracy 75.85\n",
            "\t Validation loss 0.00534, Validation accuracy 58.70\n",
            "Validation loss increased from 0.00 to 0.01\n",
            "Early stopping at epoch 22\n",
            "After training:\n",
            "\t Training loss 0.00499, Training accuracy 77.13\n",
            "\t Validation loss 0.00534, Validation accuracy 58.70\n",
            "\t Test loss 0.00549, Test accuracy 58.69\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# cifar10, resnet18, early stopping \n",
        "_, _ = main_early_stop(early_stopping=True, cifar10=True, resnet18=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
